---
title: Primality Testing
pyodide:
  resources:
    - ../src
---

In @sec-trial-division we saw that often the worst-case input for trial division was prime numbers: to rule out that these had any nontrivial factors, we had to test every single prime factor between 2 and $\sqrt{n}$. This is a problem because many numbers that we wish to factor in practice have a form like this, where there are many small factors but one big factor:

62104940417054684654 = 2 × 17 × 541 × 1223 × 2760727302517

With our approach so far, we'd spend most of our runtime just ensuring that the large cofactor 2760727302517 is in fact prime:

```{pyodide}
#| autorun: true
#| runbutton: false
#| edit: false
#| output: false
import sys
if "src" not in sys.path:
    sys.path.insert(0, "src")
```

```{pyodide}
from chapter1 import trial_division_wheel_30030
import timeit

n = 62104940417054684654
while n != 1:
    f = trial_division_wheel_30030(n)
    t = timeit.timeit(lambda: trial_division_wheel_30030(n), number=10)
    print(f"Found factor {f} in time {t}")
    n //= f
```

But what if there were a way to determine if a number is prime quickly without having to test all possible factors? The main idea is: if we can find mathematical properties that prime numbers satisfy but composite numbers don't, we can use that to differentiate them.

## Fermat primality test {#sec-fermat-primality-test}

Our first primality test is based on **Fermat's Little Theorem**, which states that:

* If *p* is prime and 1 < *a* < *p*, then a^p^ % *p* = a. (where % is remainder after division)

For example, given the prime *p* = 11 and *a* = 2, we can compute 2^11^ % 11 = 2048 % 11 = 2. The contrapositive is also true:

* If 1 < *a* < *n* and *a*^n^ % *n* ≠ *a*, then *n* is composite. An *a* satisfying this is called a *witness*.

For example, 2^15^ % 15 = 32768 % 15 = 8 ≠ 2, showing 15 is composite (and 2 is a witness). Note that this doesn't tell us any factor of 15, only that it *has* factors.

We begin by investigating a^n^ for various *a* and *n* to see when the property `a**n % n == a` is satisfied. For efficiency we replace `a**n % n` by the much faster equivalent `pow(a, n, n)` ― we will explore in @sec-modular-exponentiation how `pow()` works in detail.

```{pyodide}
def test_fermat_property(n):
    print(f"\n{n}: ", end="")
    for a in range(2, n-1):
        if pow(a, n, n) == a:  # a**n % n == a
            print("T", end="")
        else:
            print("F", end="")
    print()

for n in [11, 13, 15, 24, 31, 35]:
    test_fermat_property(n)
```

For primes like 11, 13, and 31, the property is always true. For most composite numbers like 15, 24, and 35, the property is false for at least half of all possible *a* values. There is no simple way to compute a witness *a* value such that *a*^n^ % *n* ≠ *a*. But because at least half the possible *a* will work, it's sufficient to just try random values of *a*. Each gives us a ≥50% chance of finding a witness, so after trying maybe 30 different values, the chance of failing to find one is < 1/2^30^, incredibly unlikely. This gives us a simple randomized primality test:

```{pyodide}
import random

def is_prime_fermat(n):
    for i in range(30):
        a = random.randint(2,n-1)
        if pow(a, n, n) != a:
            return False
    return True

for n in [11, 13, 15, 24, 31, 35]:
    print(f"{n} prime: {is_prime_fermat(n)}")
```

It can seem strange at first to accept a small chance of failure. However, in the real world hardware failures causing incorrect results are much more likely than 1/2^30^, so this is not an issue in practice.

Unfortunately, there is a bigger problem with this test: there are certain special composite numbers *n* called Carmichael numbers (like 561 = 3 × 11 × 17) that always satisfy the Fermat property for all *a*, just like a prime number, and it will incorrectly return `True` for these:

```{pyodide}
test_fermat_property(561)
is_prime_fermat(561)
```

## Miller-Rabin to the rescue

## Speeding up exponentiation mod n {#sec-modular-exponentiation}

We begin with the problem that it's too slow to compute *a*^n^ for large *n*. For example, if *a*=2 and *n*=1000000, then `2**1000000 % 13` computes a massive, 301030-digit intermediate value, only to reduce it to 3 afterwards. Instead, we can aggressively take the remainder during the exponentiation computation, every time we exceed 13:

```{pyodide}
import timeit

# Find a**k % n
def power_mod_slow(a, k, n):
    result = 1
    for i in range(k):
        result *= a
        if result >= n:
            result = result % n
    return result            

print(timeit.timeit(lambda: 2**1000000 % 13, number=1))
print(timeit.timeit(lambda: power_mod_slow(2, 1000000, 13), number=1))
```

But this version is still too slow, because it computes the power by repeated multiplication 1000000 times. Instead, we can take advantage of the fact that:

2^1000000^ = (((((2^10^)^10^)^10^)^10^)^10^)^10^

to compute the result like this:

```{pyodide}
import timeit
print(timeit.timeit(lambda: 2**1000000 % 13, number=10)/10)
print(timeit.timeit(lambda: \
    (((((2**10 % 13)**10 % 13)**10 % 13)**10 % 13)**10 % 13)**10 % 13, number=100000)/100000)
```

This is dramatically faster. Suppose we had a more complex power like 2^547^. In this case, we can write it like this:

547 = (((5 × 10) + 4) × 10) + 7

2^547^ = ((2^5^)^10^ × 2^4^)^10^ × 2^7^

This suggests a general solution. We extract the decimal digits of the power *k* and then alternate between exponentiating by 10 and multiplying by `a**digit` for each digit:

```{pyodide}
import timeit

# Find a**k % n
def power_mod_decimal(a, k, n):
    digits = []
    while k > 0:
        digits.append(k % 10)
        k //= 10
    digits.reverse()

    result = 1
    for digit in digits:
        result **= 10
        result *= a**digit
        result %= n
    return result

print(timeit.timeit(lambda: 2**123456789 % 13, number=1))
print(timeit.timeit(lambda: power_mod_decimal(2, 123456789, 13), number=1000)/1000)
(2**123456789 % 13, power_mod_decimal(2, 123456789, 13))
```

This works well, but improvements can be made by switching from base 10 to another base. Which base is optimal depends on the precise input parameters, but binary has some big advantages for large inputs:

* Extracting the digits from *k* with bit operations is fast.
* Exponentiation by 2 can be replaced with a single multiplication.
* Most importantly, the size of intermediate results never exceeds *n*^2^.

```{pyodide}
import timeit

def power_mod_binary(a, k, n):
    digits = []
    while k > 0:
        digits.append(k & 1)
        k >>= 1
    digits.reverse()

    result = 1
    for digit in digits:
        result *= result
        if digit:
            result %= n
            result *= a
        result %= n
    return result

a, k, n = 2, 123456789, 13
print(timeit.timeit(lambda: power_mod_decimal(a, k, n), number=10000))
print(timeit.timeit(lambda: power_mod_binary(a, k, n), number=10000))
print(timeit.timeit(lambda: pow(a, k, n), number=10000))
print()
a, k, n = 10**1000//2 - 3, 10**1000, 10**1000
print(timeit.timeit(lambda: power_mod_decimal(a, k, n), number=1))
print(timeit.timeit(lambda: power_mod_binary(a, k, n), number=1))
print(timeit.timeit(lambda: pow(a, k, n), number=1))
(power_mod_binary(a, k, n), pow(a, k, n))
```

On small inputs, the large digit count of the binary version creates substantial overhead, but on large inputs, its smaller intermediate results allow it to even approach the performance of Python's built-in `pow()`.

### Miller-Rabin primality test

We now return to the remaining problem with the Fermat primality test: false positives. We know that if *a*^n^ % *n* = *a* ever fails, the number is composite, but what if this condition never fails? For most composite numbers, about 50% of all possible *a* will cause this condition to fail, meaning that if we try about 20 random values of *a*, the chance of a false positive is vanishingly small (1/2^20^), so small in fact that hardware failure is more likely. But there are special composite numbers, called Carmichael numbers, that satisfy *a*^n^ % *n* = *a* for all possible *a*, just like prime numbers. Fermat's Little Theorem cannot distinguish them from primes.

To fix this, we introduce a new property called the **Square Roots of Unity Property**. This states that:

* If *p* is prime, then for all 2 ≤ *x* ≤ *p*−2, *x*^2^ % p ≠ 1.

A value *x* such that *x*^2^ % p = 1 is called a **square root of unity**. The values 1 and *p*−1 are always square roots of unity. The above property states that there are no others.

Proof: If *x*^2^ % p = 1, that means *x*^2^ - 1 = (*x* − 1)(*x* + 1) is divisible by *p*. And if a prime *p* divides a product, it must divide either one factor or the other. This implies *x* must be of the form *kp* − 1 or *kp* + 1. Either way it's not between 2 and *p*−2.

The contrapositive of this property states:

* If there exists an *x* in 2 ≤ *x* ≤ *n*−2 with *x*^2^ % n = 1, then *n* is composite.

Miller-Rabin extends the basic Fermat primality test to also search for these square roots of unity, in order to prove that *n* is composite. This test is strong enough to catch Carmichael numbers.

## Primality certificates

In practice, the chance of Miller-Rabin failing is so tiny as to be irrelevant. But in certain special applications, it's still useful to be able to prove with certainty that a number is prime. Although there are deterministic algorithms to determine if a number is prime with certainty (the AKS algorithm), these are impractical for real-world use.

Instead, we'll pursue a different approach where we construct a **primality certificate**, a set of information that anyone can use to quickly verify that a given number is prime. Verifying that the certificate is valid is easy and fast, but finding it is difficult and requires some advanced techniques and heuristics. These techniques will help us prepare for more advanced factoring techniques later in this book.

### Pratt certificates

### Congruence modulo n notation

First, to make it easier to discuss remainders, we introduce this standard math notation for **congruence modulo n**:

$$ a \equiv b \pmod{n} $$

This simply means `a % n == b % n`. For example:

* 17 ☰ 5 (mod 4)  (because `17 % 4 == 5 % 4 == 1`)
* 5 ☰ 2 (mod 3)  (because `5 % 3 == 2 % 3 == 2`)
* 15 ☰ 0 (mod 5)  (because `15 % 5 == 0 % 5 == 0`)

A congruence like this is a lot like an equation: as long as we add, subtract, or multiply both sides by the same number, it will remain true. Dividing both sides by the same number is also allowed, but *only under the condition* that the divisor and *n* have no factors in common. Otherwise something like this can happen:

* 30 ☰ 15 (mod 5) ✅
* 6 ☰ 3 (mod 5) ❌ (breaks when dividing both sides by 5)
* 10 ☰ 5 (mod 5) ✅ (dividing both sides by 3 is okay, 3 has no factors in common with 5)

Using this notation, we can rewrite Fermat's Little Theorem like this:

$$ p\text{ prime}, 1 < a < p \implies a^p \equiv a \pmod p $$

You may also see this written $a^{p-1} \equiv 1 \pmod p$, found by dividing both sides by $a$ (which shares no factors with $p$ so this is okay).

### The group $\mathbb{Z}_p^*$

### Order of an element and Lagrange's theorem

Take a look at the powers of 3 mod 7:

3, 9, 27, 81, ... (mod 7)

3, 2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3, ...

They form a cycle that repeats every 6 powers. This cycle length 6 is called the **order** of 3 in the group $\mathbb{Z}_7^*$. This helps explain why Fermat's Little Theorem is true: if we repeat every *n*−1 powers, and we started at a power of 1, we must come back around to where we started at the power *n*.

If we do the same thing with other values of *a*, it still repeats every 6 powers, but for some elements it may also repeat even faster than that:

::: {style="width: 50%;"}
| a | a^1^ | a^2^ | a^3^ | a^4^ | a^5^ | a^6^ | a^7^ |
|---|---|---|---|---|---|---|---|
| **2** | 2 | 4 | 1 | 2 | 4 | 1 | 2 |
| **3** | 3 | 2 | 6 | 4 | 5 | 1 | 3 |
| **4** | 4 | 2 | 1 | 4 | 2 | 1 | 4 |
| **5** | 5 | 4 | 6 | 2 | 3 | 1 | 5 |
| **6** | 6 | 1 | 6 | 1 | 6 | 1 | 6 |
::: 

Some elements have order 6, some order 3, and some order 2. All of them have order that is a factor of 6. In general, in the integers mod *p* for any prime *p*, all 1 ≤ *a* ≤ n-1 will have an order dividing *p*-1.

In group theory terms, this is a special case of Lagrange's Theorem, which says that any subgroup of a group will have a size that divides the size of the full group. Here the full group is $\mathbb{Z}_p^*$, the numbers 1 through *p*-1 with the operation of multiplication mod *p*, which has size *p*-1.

